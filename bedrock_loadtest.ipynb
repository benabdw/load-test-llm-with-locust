{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59f6f8-e517-49ba-bad0-030ce7814e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Boto3 client for Bedrock Runtime\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n",
    "\n",
    "prompt = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0.1,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"story of two dogs\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "# formatting the prompt as a json string\n",
    "json_body = json.dumps(prompt)    \n",
    "\n",
    "\n",
    "# # Define the prompt and other parameters\n",
    "# prompt = \"\\n\\nHuman: story of two dogs\\n\\nAssistant:\"\n",
    "modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "# accept = 'application/json'\n",
    "# contentType = 'application/json'\n",
    "\n",
    "# invoking Claude 3.5, passing in our prompt\n",
    "response = bedrock_client.invoke_model(body=json_body, modelId=modelId,\n",
    "                                    accept=\"application/json\", contentType=\"application/json\")\n",
    "\n",
    "\n",
    "# Process the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body['content'][0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d7ca0-90df-4be4-b7a5-3e5aef2ffe87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Boto3 client for Bedrock Runtime\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n",
    "\n",
    "max_tokens_to_sample = 200\n",
    "\n",
    "# Define the prompt and other parameters\n",
    "prompt_data = f\"\"\"\n",
    "Write a long and high-quality story about two dogs. Make the story longer than {max_tokens_to_sample}\n",
    "\n",
    "Rex and Charlie were best friends who did everything together. They lived next door to each other with their human families and spent all day playing in the backyard. Rex was a golden retriever, always happy and eager for fun. Charlie was a German shepherd, more serious but very loyal. \n",
    "\n",
    "Every morning, Rex and Charlie would wake up and bark excitedly, ready to start the day's adventures. Their families would let them out into the backyard and they'd run around chasing each other and sniffing for interesting smells. After tiring themselves out, they'd nap in the shade of the big oak tree, Rex's tail still thumping contentedly even in his sleep. \n",
    "\"\"\"\n",
    "\n",
    "prompt = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_data\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "# formatting the prompt as a json string\n",
    "json_body = json.dumps(prompt)    \n",
    "\n",
    "# modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "modelId = 'anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "\n",
    "# invoking Claude 3.5, passing in our prompt\n",
    "response = bedrock_client.invoke_model(body=json_body, modelId=modelId,\n",
    "                                    accept=\"application/json\", contentType=\"application/json\")\n",
    "\n",
    "\n",
    "# Process the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509bca9-c543-4dc4-8dd3-e3a9e7d5a3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_client.invoke_model(\n",
    "    modelId=modelId,\n",
    "    accept=accept,\n",
    "    contentType=contentType,\n",
    "    body=body\n",
    ")\n",
    "# Process the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "logging.info(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67072e8b-35f1-4786-a7b0-55d1e446615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc085be-240d-422e-a026-0a59134cf0c6",
   "metadata": {},
   "source": [
    "### Testing the throughput and lantency with locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac579ad7-1714-4be7-bd14-130a80939f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb3667-54b5-414e-8a24-6c9b240e3841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile locustfile.py\n",
    "\n",
    "from locust import User, task, between\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Boto3 client for Bedrock Runtime\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime',region_name='us-west-2')\n",
    "\n",
    "max_tokens_to_sample = 200\n",
    "\n",
    "# Define the prompt and other parameters\n",
    "prompt_data = f\"\"\"\n",
    "Write a long and high-quality story about two dogs. Make the story longer than {max_tokens_to_sample}\n",
    "\n",
    "Rex and Charlie were best friends who did everything together. They lived next door to each other with their human families and spent all day playing in the backyard. Rex was a golden retriever, always happy and eager for fun. Charlie was a German shepherd, more serious but very loyal. \n",
    "\n",
    "Every morning, Rex and Charlie would wake up and bark excitedly, ready to start the day's adventures. Their families would let them out into the backyard and they'd run around chasing each other and sniffing for interesting smells. After tiring themselves out, they'd nap in the shade of the big oak tree, Rex's tail still thumping contentedly even in his sleep. \n",
    "\"\"\"\n",
    "\n",
    "prompt = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_data\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "# formatting the prompt as a json string\n",
    "json_body = json.dumps(prompt)    \n",
    "\n",
    "# modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "modelId = 'anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "\n",
    "class LLMUser(User):\n",
    "    @task\n",
    "    def generation(self):\n",
    "        # Invoke the model\n",
    "        with self.environment.events.request.measure(\"[Send]\", \"Prompt\"):            \n",
    "            response = bedrock_client.invoke_model(body=json_body, modelId=modelId,\n",
    "                                    accept=\"application/json\", contentType=\"application/json\")\n",
    "            # Process the response\n",
    "            response_body = json.loads(response.get('body').read())\n",
    "            logging.info(response_body['content'][0]['text'])\n",
    "            \n",
    "        logging.info(\"Finished generation!\")            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe08be-e37e-4e59-9036-44e649954fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "875f7987-18bc-4deb-98b3-71a4e712c983",
   "metadata": {},
   "source": [
    "The configuration with Command Line Options https://docs.locust.io/en/stable/configuration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db38d4-b323-463f-836d-51905c0e46a1",
   "metadata": {},
   "source": [
    "--users <int> Peak number of concurrent Locust users. Primarily used together with --headless or --autostart.\n",
    "    \n",
    "--headless Disable the web interface, and start the test immediately.\n",
    "    \n",
    "--csv Store request stats to files in CSV format.\n",
    "\n",
    "--spawn-rate <float> Rate to spawn users at (users per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92b060-de61-4d6f-a63f-8225449ba41f",
   "metadata": {},
   "source": [
    "In this example, the --users option sets the total number of users to 30, and the --spawn-rate option sets the rate of user spawning to 30 users per second. By using the same value for --spawn-rate as the total number of users, all 30 users will be spawned immediately. Therefore, at any given time during the test, there will be a maximum of 30 concurrent users.\n",
    "\n",
    "Please note that the --run-time option sets the duration of the test in seconds. In this example, the test will run for 120 seconds before stopping.\n",
    "\n",
    "!locust --headless --users 10 --spawn-rate 10 --run-time 120 --csv ./benchmark_metric/benchmark_u30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa215728-03ec-4a37-85b8-2d7a625eeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!locust --headless --users 30 --spawn-rate 30 --run-time 120 --csv ./benchmark_metric/benchmark_u30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be37908-7c39-4756-bf28-0140d5ffa201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c7338-1358-4759-8577-fa26b14cad32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
